{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haydnllh/pi_c_maths/blob/main/%F0%9F%A4%93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_dJzAWSAFbL"
      },
      "source": [
        "This is my first machine learning program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i4UO8p2zsnPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a86339-f7c7-44ca-b6c2-80dd1cf4bcda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "!pip install -q rembg\n",
        "import rembg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqoma3VLy3U9",
        "outputId": "f5317db0-0c4d-43dc-ca5e-c651b9863027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O7SD_GKKrhAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6ba7b0-413a-4291-d22d-8b4f377b11b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading handwrittenmathsymbols.zip to /content\n",
            " 97% 334M/343M [00:03<00:00, 94.7MB/s]\n",
            "100% 343M/343M [00:03<00:00, 103MB/s] \n"
          ]
        }
      ],
      "source": [
        "#load kaggle handwritten maths symbols dataset\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d xainano/handwrittenmathsymbols\n",
        "!unzip -q handwrittenmathsymbols.zip\n",
        "!unrar x -inul -y \"data.rar\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(image, d):\n",
        "  (image_h, image_w) = image.shape\n",
        "  ar = image_w/image_h\n",
        "  re_dim = d - d//10\n",
        "  re_dim_y = int(re_dim*ar)\n",
        "  re_dim_x = int(re_dim//ar)\n",
        "  oe = int(not bool(d%2))\n",
        "  if re_dim_y % 2 == oe:\n",
        "    re_dim_y += 1\n",
        "  elif re_dim_x % 2 == oe:\n",
        "    re_dim_x += 1\n",
        "  if ar > 1:\n",
        "    resized = cv2.resize(image, (re_dim,re_dim_x))\n",
        "  else:\n",
        "    resized = cv2.resize(image, (re_dim_y,re_dim))\n",
        "  (re_h,re_w) = resized.shape\n",
        "  img_box = np.zeros([d,d],\"uint8\")\n",
        "  bound_y = round((d-re_h)/2)\n",
        "  bound_x = round((d-re_w)/2)\n",
        "  img_box[bound_y:d-bound_y,bound_x:d-bound_x] = resized\n",
        "  return img_box"
      ],
      "metadata": {
        "id": "iKL3fjnUU_ly"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nV95OKOQ_DCa"
      },
      "outputs": [],
      "source": [
        "#remove background with rembg\n",
        "#segment image by connected component labeling\n",
        "def img_segment(image, dimension):\n",
        "  kernel = np.ones((5, 5), np.uint8)\n",
        "  (image_width,image_height) = image.shape[:2]\n",
        "  image_rembg = rembg.remove(image)\n",
        "  image_rembg = cv2.morphologyEx(image_rembg, cv2.MORPH_OPEN, kernel, iterations = 3)\n",
        "  gray = cv2.cvtColor(image_rembg, cv2.COLOR_BGR2GRAY)\n",
        "  blurred = cv2.blur(gray, (7,7))\n",
        "  thresh = cv2.threshold(blurred, 10, 255, cv2.THRESH_BINARY)[1] #threshold the image\n",
        "  dilated_image = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "  thresh_transpose = dilated_image.T #do the algorithm column by column\n",
        "  output = cv2.connectedComponentsWithStats(thresh_transpose, 4, cv2.CV_32S)\n",
        "  (numLabels, labels, stats, centroids) = output\n",
        "  #storing the components\n",
        "  component_list = []\n",
        "  for i in range(1, numLabels):\n",
        "    bounding_box_x = stats[i, cv2.CC_STAT_LEFT]\n",
        "    bounding_box_y = stats[i, cv2.CC_STAT_TOP]\n",
        "    bounding_box_width = stats[i, cv2.CC_STAT_WIDTH]\n",
        "    bounding_box_height = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "    bounding_box_area = stats[i, cv2.CC_STAT_AREA]\n",
        "    bounding_box = labels[bounding_box_y: bounding_box_y + bounding_box_height, bounding_box_x: bounding_box_x + bounding_box_width]\n",
        "    component = (bounding_box == i).astype(\"uint8\") * 255\n",
        "    resized = resize(component.T, dimension) #resizing to the desired input size\n",
        "    print(i-1)\n",
        "    cv2_imshow(resized)\n",
        "    resized = np.expand_dims(resized, axis=2)\n",
        "    input = np.expand_dims(resized, axis=0)\n",
        "    component_list.append(input)\n",
        "  return component_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"/content/IMG_1721.jpg\")\n",
        "op_list = img_segment(image,45)\n",
        "mnist_list = img_segment(image,28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "USTxXERRVSX0",
        "outputId": "fae5f391-723b-43a0-a4db-f569fe491343"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n",
            "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 132GB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=45x45>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAAAtCAAAAAAfcb1GAAAAgUlEQVR4nO2U2Q2AIBBEd42VWZvl2JZ1jJ8CznAkYCRx/mDfnhxmr+gEGmjENHNdpC/DJU2Vob1f7K2CDtIhXKFcCbFn6KLmp48KWk4YPU8+Fn8YI2cSdcmN8GRD4Skkr13gezOrDGj+nHlbl5nYpEwVe2/KafSb++Jr+OnZ6ZG6AG4LFpz1LUc8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=45x45>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAAAtCAAAAAAfcb1GAAAA20lEQVR4nL1VMQ7CMBDzIUa+1Z8xwMIDmNjZmPmbGVCbqLFzrUq5qcq5jhtfXOC/dSNJ2Yl2ib51sGAI+hYNABEBgOdUCcdFiu6c+zJhQoiZv10zsmlr3a4EeliF7tQ23cLARImeEYku5ASu6c61mZmXxUOlR+g+TU93L3OuRQjRJ2bvg/QyHJO5DXK1OyfvxSxco+RRXlnATdOU3KP5DbmbwZC7mjMxHy/Qfrw3uzNRD3n61Jdgh/TZF23PsEU/O9zuvxMy7o+CoORDnj6odOfpAyC+qFc/Qn9cH1N7L9o0uKGNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=45x45>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAAAtCAAAAAAfcb1GAAABL0lEQVR4nMWUMU4DMRBFvw0NINFHkBIJiYqCG+QWSByBjppDcAgaeu5AxRkocoBIqR8FXq/tGZuNhMSv7Jnn77/jKNJ/C+BkIXsOAMvgCw6gb5jp8BucLYOkOGbvK1jH+bx3S5s15przFUUpZLpj5JyPw25jragicY2bHMn7ysM3Fk6LmSJHw8Ip97wPrBs4OqOlkCQ9pfXOohafVisfrvC78pZSRSg7bpM4Dnr288q3DNe9lP55+i3jLYXHQ7zdH0fXW+uxd60P6kcaagvL8T3A6mshDsARbPTSwZ2XD2aTFX1YYZuqZ26Mt3T3aR0Mnh341UlqK1MuNydtLQ7gaUdD9wbb4nEEGzxK2rdNK2Y6D+22a17+PyW9+7bNHH+2l90UzdSBhx6b8M9B/2/0DTfq/IB6KeloAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=45x45>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAAAtCAAAAAAfcb1GAAAAl0lEQVR4nO2UwQ2AMAwDG4QYgt2YiZmYzPwAJXZppVJ4kFeLT5aRq6TUeSYAAKJgBIZUI42MPOQzuTQj1Y2QzPuE2S/dJMnTizN1/u56CZIQZZKEVaDpzGh6Jd9I7kvs4i5JN5qmsKA3Dsd3omyZt4mzSHIgMyspJDHWuKS7NP/Tn6fd623mXbA13dTt7zrvp+jW2/7F2QHR2xkgXhc3cAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=45x45>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAAAtCAAAAAAfcb1GAAAAXUlEQVR4nO2UMQ4AIAgD1cfqG3y7Qx1c20Qj3egIR0NQKMWnSqMQicaC8xRcekNlqLdUAD1ivLkA9H9vJx3w8m+d0Hm8e8tf5eo76aTjaef1WQA9yLk73zSXGLdVGyCcEU2okdugAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAATklEQVR4nGNgIAL8xybIhCb3XwKLRpgsiglM+OwiRfI48Trp4yC8kqiuZUR2ByMDw39GXJIYwmjgPwPDf7i/WLAowK4N3Xz6BMIgl8QLADN/EsTE0sJ9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgklEQVR4nI2S0RGAMAhDwSFcwbH9dCeXiR/tnUloq3y0J+FB5BqxiOQPWGIzrR1VRESmqClau3NA1mAxV+K5aALwVWbuXyiB5hZabW6BuCRhJGW0rf3p7w21tjO3sMYs3oP1viDe00mUapl5mEhDup3xS6C9VbKjRJZ3yzkxlLV+Hg+QRiMfcdYSDwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoklEQVR4nH2RwRECIQxFE8Y27MKbzexYhO3YgQV49mYRW8rzgEh+gM2Bgf9I8glmB+ELHTO3MkU763JvAOZlaQ1Pde8D26qKGqM7LSoJs9KS1J/3NdwmME3z1N9TS/FWshC3ZZRG+Kc+g4eZNxuttbjAHX6/kQN4YYnGd7qlXyjKZJwVPsN1oWZ21k4Au5yiSYDPglXlGqC869EVYBjidBYaX1BrX/mN8hPrAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeklEQVR4nLWRyxGAMAhEdx1rsARtI/bfjB3ghRgChJt7yIfHEiYAhWgv4iKbZ7p6KMBDWsoJsq/eqdE7bUihmJBtKMhCVlCL51Acw760TU72zad05wFABpzKEkArul28+ekq0vORdZ2Vc1iDs5lz+Ox82Il+glGLoQS9N9QZN6tH+s4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAOElEQVR4nGNgIBr8/78GmcuIIocmwITPIOIlF5Ctk5DkApySCVSzEz2EUPjU88qoJPmSa/GpRAcA1lsHKL1UC9sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eu89jZlhpKl",
        "outputId": "f5d071dd-3f49-485a-fe38-82ba57714211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 157485 files belonging to 14 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CacheDataset element_spec=(TensorSpec(shape=(None, 45, 45, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#process dataset\n",
        "def function(x,y):\n",
        "  image = tf.where(x < 10, x, 255)\n",
        "  return image, y\n",
        "desired_class = ['+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'times', 'div']\n",
        "path = \"/content/extracted_images\"\n",
        "for folders in os.listdir(path):\n",
        "  if folders not in desired_class:\n",
        "    shutil.rmtree(os.path.join(path,folders))\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/extracted_images\",\n",
        "    labels = \"inferred\",\n",
        "    color_mode = 'grayscale',\n",
        "    image_size = (45,45),\n",
        "    batch_size = 1024,\n",
        "    class_names = desired_class,\n",
        "    shuffle = True,\n",
        "    seed = 719,\n",
        ")\n",
        "ds_train = ds_train.map(function)\n",
        "ds_train.cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCphufZUUQIH",
        "outputId": "93f644ae-2ac0-4cc6-b00e-c56a3c2d0250"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3MW78-Z4rYJv"
      },
      "outputs": [],
      "source": [
        "#defining model\n",
        "model_mnist = keras.Sequential([\n",
        "    layers.Conv2D(filters = 8, kernel_size = 5, activation = \"relu\", padding = 'same', input_shape = [28,28,1]),\n",
        "    layers.Conv2D(filters = 16, kernel_size = 3, activation = \"relu\", padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units = 10, activation = \"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Sequential([\n",
        "    layers.Conv2D(filters = 8, kernel_size = 5, activation = \"relu\", padding = 'same', input_shape = [45,45,1]),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    layers.Conv2D(filters = 16, kernel_size = 3, activation = \"relu\", padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units = 14, activation = \"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "MYE0fPT6ZHPW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVITb_KAKKIx",
        "outputId": "fe625525-25f5-4e98-96ed-2f6e4c5ab45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 5s - loss: 0.4280 - accuracy: 0.9335 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 6s - loss: 0.0740 - accuracy: 0.9782 - 6s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - loss: 0.0550 - accuracy: 0.9830 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 5s - loss: 0.0475 - accuracy: 0.9853 - 5s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 6s - loss: 0.0402 - accuracy: 0.9871 - 6s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7982044c5d50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#defining optimiser, loss function and metrics\n",
        "model_mnist.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#fitting\n",
        "model_mnist.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 5,\n",
        "    verbose = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#fitting\n",
        "model_2.fit(\n",
        "    ds_train,\n",
        "    epochs = 2,\n",
        "    verbose = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9y9Z68jZzSd",
        "outputId": "d4adb1c8-1a32-4baf-f43a-d0ade21da8f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "154/154 - 16s - loss: 5.3346 - accuracy: 0.6358 - 16s/epoch - 107ms/step\n",
            "Epoch 2/2\n",
            "154/154 - 13s - loss: 0.6021 - accuracy: 0.8657 - 13s/epoch - 85ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7982413d3490>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mpW0FVrND0EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee859d7a-1a85-4c35-8317-c678da292fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "The answer is 4368 [48, 91] []\n"
          ]
        }
      ],
      "source": [
        "#maths part\n",
        "numbers, stack, operation_queue = [], [], []\n",
        "for i in range(len(mnist_list)):\n",
        "  number = str(np.argmax(model_mnist.predict(mnist_list[i])))\n",
        "  operator = np.argmax(model_2.predict(op_list[i]))\n",
        "  if 2 <= operator <= 11:\n",
        "    stack.append(number)\n",
        "  else:\n",
        "    number = int(\"\".join(stack))\n",
        "    stack.clear()\n",
        "    numbers.append(number)\n",
        "    operation_queue.append(operator)\n",
        "number = int(\"\".join(stack))\n",
        "stack.clear()\n",
        "numbers.append(number)\n",
        "stack.append(numbers[0])\n",
        "n3 = 0\n",
        "for i in range(1,len(numbers)):\n",
        "  n1 = stack.pop()\n",
        "  n2 = numbers[i]\n",
        "  match operation_queue.pop(0):\n",
        "    case 0:\n",
        "      n3 = n1 + n2\n",
        "    case 1:\n",
        "      n3 = n1 - n2\n",
        "    case 12:\n",
        "      n3 = n1 * n2\n",
        "    case 13:\n",
        "      n3 = n1 / n2\n",
        "  stack.append(n3)\n",
        "print(\"The answer is\", stack.pop(), numbers, operation_queue)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}